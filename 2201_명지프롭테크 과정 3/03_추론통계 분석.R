
###############
# 3주_추론통계
##############

#----------------------------------
# 0_기술통계를 넘어서 추론통계로...
#----------------------------------

# 01_통계적 추론(statistical inference)이란?

# 모집단에 대한 어떤 미지의 양상을 알기 위해 통계학을 이용하여 추측하는 과정
# 모집단에 대한 추론을 100% 확신하기 위해서는 모집단 전체를 표본으로 조사해야 함
# 그러나 비용 또는 시간 등의 이유로 불가능한 경우가 많기 때문에 표본에서 얻은 정보를 가지고 추론하게 됨

# 02_왜 가정을 하는가?

# 표본은 모집단에서 추출된 것임(부분집합) 
# ⇒ 충분히 많은 수의 표본이 있다면 모집단에 대해 정확히 이해할 수 있음
# 문제는 우리에게 주어진 것은 표본이 제한적이라는 것임
# 부분집단에 대한 정보만 존재하고 전체 집단에 대한 정보는 존재하지 않음
# 따라서 표본과 모집단이 비슷한 형태를 가지고 있다는 확신이 없음

# 03_추론통계의 핵심: 믿음  

# 그렇다면 우리는 어떻게 확신을 가질 수 있을까?
# 믿으세요... “오직 믿음만이 여러분을 통계의 지옥에서 구원할 것입니다~”

#--------------------
# 통계는 믿음이다 !!!
#--------------------

# 위에서 “믿음”이라는 은유적 표현을 사용하였지만 학문적으로는 「믿음 ⇒ 가정」
# 따라서 우리는 다음과 같은 믿음을 가지고 자료를 분석함

#-----------------------------------------------------------------------
# 우리에게 주어진 데이터(표본집단)가 우리가 알 수 없는 전체집단(모집단)을 
# 대표할 수 있다고 통계학적으로 가정하고(믿고) ⇒ 표본 집단의 특성을 분석
# 함으로써 모집단의 특성을 추론(대충 어림잡아 짐작)할 수 있음
#------------------------------------------------------------------------

# 04_자료특성에 따른 추론통계의 구분: 모수통계와 비모수통계  

# 통계적 추론은 자료의 특성에 따라 모수적 / 비모수적 방법 두 가지로 구분됨
# 모수 / 비모수를 구분하는 핵심은 “표본(sample data)이 정규분포를 가지고 있는가?”임

# 1) 표본이 최소 30개 이상(30<n)인 경우 → 정규분포 가정하고 모수적 방법을 사용
# 2) 표본이 10≤n≤30인 경우 → 정규성 검정(power analysis)을 실시함

# 정규성 검정을 통과한 경우        →   모수적 방법을 사용하여 추론함
# 정규성 검정을 통과하지 못한 경우 → 비모수적 방법을 사용하여 추론함
# (정규성 검정을 통과하면 정규분포를 가진 경우라고 가정하기 때문임)


#---------------------
# 1_기본가정: 정규분포
#---------------------

# 01_정규분포곡선 그리기

# 정규분포란 무엇인가?
# 이항분포의 시행횟수를 극한으로 증가시키면 -> 정규분포가 됨

x <- seq(-3 ,3 ,length= 100)   # -3 ~ 3 사이의 숫자 임의로 100개 생성
y <- dnorm(x, mean=0, sd=1)    # dnom(density-normalization:확률밀도함수) 생성: 평균 0 / 표준편차 1
plot(x, y, type="l", lwd=1)    # 플로팅

# 02_정규분포의 특성

# 1) 모든 정규분포는 종 모양을 나타내고 좌우 대칭
#    평균을 중심으로 좌우 대칭이며 종 모양을 나타냄
#    따라서 정규분포를 따르는 확률변수 X는 평균 중앙치 최빈치가 모두 같음
#    그런데 확률변수 X 가 갖는 범위는 무한대일 수 있음
#    확률의 모든 값을 표현하기 때문에 최댓값과 최솟값이 별도로 존재하는 것이 아니라 무한대 영역을 가짐
#    따라서 곡선축과 X축이 서로 떨어져 있음

# 2) 정규곡선의 위치는 평균 μ 에 의해서 정해지고, 그 모양은 표준편차 σ 크기에 의해서 결정됨
#    어떤 정규분포에서 μ = 10 일 때 정규곡선 중심 위치는 10 이고, μ = 30 이면 정규곡선 중심 위치는 30
#    표준편차가 작으면 정규분포는 좁게 밀집된 모양으로 나타나고, 표준편차가 크면 넓게 흩어진 형태로 나타남
#    표준편차가 일정할 때, μ(평균)가 커지면 오른쪽으로 이동함

# 3) 자료집단에 따라 평균과 표준편차 크기는 다름
#    그러나 평균으로부터 k 배 표준편차 이내 범위에서 확률변수 X 값을 갖게 될 확률은 같음
#    확률변수 X가 평균이 μ 이고 분산이 σ인 정규분포 한다면, μ 로부터 ±σ, ±2σ, ±3σ 범위 내에 
#    확률변수 값이 포함된 확률은 각각 68.3 %, 95.4 %, 99.7 % 임
#    m 이 일정할 때, (표준편차)가 커지면 분포곡선이 퍼짐  

# 03_정규분포 모양: 평균과 표준편차에 따라 달라짐

x <- seq(5 ,15 ,length= 100)   # 5 ~ 15 사이의 숫자 임의로 100개 생성
y <- dnorm(x, mean=10, sd=4)    # dnom(density-normalization:확률밀도함수) 생성: 평균 10 / 표준편차 4
plot(x, y, type="l", lwd=1, xlim =c(0, 20), ylim=c(0, 0.1))    # 플로팅

x1 <- seq(6, 18 ,length= 100)   # -3 ~ 3 사이의 숫자 임의로 100개 생성
y1 <- dnorm(x1, mean=12, sd=7)    # dnom(density-normalization:확률밀도함수) 생성: 평균 0 / 표준편차 1
lines(x1, y1, col="red")    # 플로팅

# 04_정규분포의 표준화

# 모든 데이터 분포의 평균값(m)을 0, 표준편차(sd)를 1로 강제로 변환시키는 것
# 이렇게 표준화 시키면 척도(단위)를 의식하지 않고 바로 사용 가능
# 이러한 표준화 분포를 표준정규분포(z-분포)라고 함

# 정규분포 => 표준정규분포 만들기 연습
# 정규분포: 기본적으로 그래프는 형태는 똑같은데 μ와 σ에 따라 그래프의 모양이 변함
# 따라서 면적으로 구하는게 까다로음 -> 이 문제를 해결하기 위하여 표준화 함
# 표준정규분포 N(0,1)가 되면 ⇒ 평균에서 표준편차의 몇 배만 큼 떨어져 있는지 알면 
# 내가 몇 %에 있는지를 알 수 있음 -> 계산이 쉬워짐

# 표준정규분포 공식은 다음과 같음
# 표준정규분포 Z = X[관측치]-μ[평균] / σ[표준편차]

# 실습: 남한 / 북한 성인 100명 키 비교
south <- rnorm(n=1000, mean = 170, sd = 10)
north <- rnorm(n=1000, mean = 150, sd = 8)
height <- data.frame(south, north)  # 데이터프레임으로 합치기

attach(height)
par( mfrow = c(2,2))        # 빈도와 확률밀도의 개념을 이해하자
hist(south, freq = TRUE, main = "남한 성인 키 빈도")
hist(north, freq = TRUE, main = "북한 성인 키 빈도")

# z값으로 표준화: a. scale() 함수 사용
height <- transform(height, 
                    z.south = scale(south), 
                    z.north = scale(north))

hist(height$z.south, freq = TRUE, main = "남한 성인 키(표준화)")
hist(height$z.north, freq = TRUE, main = "북한 성인 키(표준화")
par( mfrow = c(1,1))

# 5_표준정규분포와 시그마

# 표준정규분포로 확률 구하기 
# 정규분포를 표준화 하면 전체 분포 가운데 나의 위치를 대략적으로 파악할 수 있음

x <- seq(-3 ,3 ,length= 100)   # -3 ~ 3 사이의 숫자 임의로 100개 생성
y <- dnorm(x, mean=0, sd=1)    # dnom(density-normalization:확률밀도함수) 생성: 평균 0 / 표준편차 1
plot(x, y, type="l", lwd=1)    # 플로팅
lines(-3:3, dnorm(-3:3), type="h", lty=3, col=c("blue", "blue", "blue", "red"))  # 표준편차 그리기 

# (시그마, 표준편차) line 추가하기 

#             *            
#            *|*       
#           * |  *      
#          *  |  | *      
#       *  |  |  |  | *                          
#     * |  |  |  |  |   *
# ---|--|--|--|--|--|--|---(2)
#   3σ  2σ 1σ 0  1σ 2σ 3σ
#          |-----|        1σ구간: 68.3%
#       |-----------|     2σ구간: 95.4%
#    |------------------| 3σ구간: 99.7%    

#----------------------------------------------------------------------------    
# Q: A반과 B반의 키 평균과 표준편차가 다음과 같다고 하자 !!!
#    평균(m) / 표준편차(sd): A 170 / 20    B 160 / 10  
#    내 키가 190이라면 평균에서 얼마만큼 떨어져 있는가? 
#  
# A: A반이라면? 190-170 = 20 / 20  = + 평균에서 1배 더 멀리 (1σ구간) ⇒ 상위 15.8%
#    B반이라면? 190-160 = 30 / 10  = + 평균에서 3배 더 멀리 (3σ구간) ⇒ 상위  0.1%
#---------------------------------------------------------------------------

# 즉, 내가 어느 집단에 속해있든 내 점수가 평균에서 표준편차의 몇 배 정도만 떨어진 지 알 수 있다면
# ⇒ 내가 상위 몇 %인지 알 수 있음

# 표준정규분포 가정의 유용성
# 따라서 우리 주변에 어떠한 사건(event)가 일어날 확률이 정규분포라고 가정하고
# 특정 사건이 정규분포의 어디에 위치하고 있는지 확률적으로 알아낸다면  ⇒ 사건의 속성을 추정하여 볼 수 있음

# 6_신뢰구간

library(tigerstats)  # install.packages("tigerstats")
pnormGC(c(-1.64, 1.64), region="between", mean=0, sd=1, graph=TRUE)  # 90% 신뢰구간
pnormGC(c(-1.96, 1.96), region="between", mean=0, sd=1, graph=TRUE)  # 95% 신뢰구간
pnormGC(c(-2.58, 2.58), region="between", mean=0, sd=1, graph=TRUE)  # 99% 신뢰구간


#------------
# 2_가설설정
#------------

# 01_# 통계적 가설이란?

# 표본(sample)을 이용하여 모집단(mother population) 추정에 대한 가설(동일성, 영향력 등) 합당성 여부를 통계적으로 추측하는 방법
# 다만 반드시 샘플-모집단의 관계에 국한되지 않고 샘플-샘플의 관계도 비교하여 분석함

# 가설검정의 본질적 목적: 비교 집단이 통계적으로 차이가 있는지 비교함

# 1) one-sample test: 관측된 한개의 표본통계량을 => 미리 알고 있는 특정 통계량(평균,분산'비율 등)과 비교 후 모집단과의 동일/차이 파악

# (i)   특정 값과 표본평균의 관계: 카탈로그에 수록되어 있는 자동차 연비와 실제 측정한 연비 사이에 차이가 있을까?
# (ii)  특정 비율과 표본비율의 관계: 지지율이 25% 이하면 내각을 해체하고 싶은데, 현재 20% => 지금 해산해야 하나? 조금 더 기다려야 하나?
# (iii) 특정 분산과 표본분산의 관계: 어느 생산 라인에서 제조된 과장 한 봉지의 용량이 허용기준에 미달될까?

# 2) two-sample test: 조건, 처리에 따라 샘플을 두 그룹으로 구분한 다음, 두 표본의 통계량이 모집단에서도 동일/차이를 보이는지 파악

# (i)    무상관 검정: 운동량과 몸무게 사이에 음의 상관관계가 있을까?
# (ii)  평균차이 검정: 남자와 여자는 성적에 차이가 있을까?
# (iii) 등분산 검정: 공장 A에서 제조된 나사와 공장 B에서 제조된 나사의 길이는 차이가 있을까?
# (iv)  비율차이 검정: A라인에서 제조된 액정패널과 B라인에서 제조된 액정패널은 수율의 차이가 있을까?

# 02_두 가설: 귀무가설과 대립가설

# 1) 귀무가설과 대립가설

# 검정에서는 모집단에 대한 가설이 옳은지 혹은 어떤지를 확률적으로 판단하기 위하여 어떤 가설을 세울것인가가 매우 중요함
# 통계적 가설은 크게 귀무가설과 대립가설로 구분할 수 있음

# (i)  귀무가설(H0): 영가설(대립가설을 0으로 돌리고자 하는 가설) => '무'로 회귀: 영향이 없음, 차이가 없음 가설
# (ii) 대립가설(H1): 연구가설(일반적으로 주장하고자 하는 사실)   =>  영향을 미침, 차이가 있음 가설

#-------------------------------------------------#------------------------------------------------
# H0: 두 표본의 (평균,분산,비율)이 차이가 없음    #  H1: 두 표본의 (평균,분산,비율)이 차이가 있음
#                                                 #
#         [모 집 단]                              #          [모집단 1]  [모집단 2] 
#          |      |                               #               |          |        
#     [표본1] == [표본2]                          #            [표본1] != [표본2]     
#                                                 #
# 동일(==): 같은 모집단에서 추출되었다고 추정     # 동일X(!=): 다른 모집단에서 추출되었다고 추정
#-------------------------------------------------#------------------------------------------------

# 2) 가설검정의 기준: 모든 가설의 출발점은 귀무가설임

# 두 데이터가 통계적으로 차이가 있을 경우 그냥 처음부터 대립가설을 검정하면 해석이 편리해지는데 왜 굳이 귀무가설에서 출발하는 것일까?
# (두 데이터가 통계적으로 차이가 있는데 귀무가설을 기준으로 가설을 검정하고, 그 결과를 해석하는 것은 이중작업에 가까움)
# 하지만 현실적으로 분석에 앞서서 두 데이터의 평균값 차이를 모르는데 어떻게 '차이가 있나? 없나?'와 같은 가설을 설정할 수 있겠는가?
# 다시말해 주장하고 싶은 가설(차이가 있다고 가정하는 대립가설: H1)은 무한으로 세울 수 있기 때문에 무한반복 분석이 필요하다는 문제에 직면
# 따라서 주장하고 싶지 않은 가설(차이가 없는 귀무가설: H0)을 세워 이를 반증하는 것이 합리적인 분석 방법임

# 03_귀무가설과 대립가설에 대하여 직관적으로 이해하기

# 집단 A(*)의 평균(μ1)과 집단 B(|)의 평균(μ2) 비교시

# H0: μ1 == μ2          # H1: μ1 != μ2 
#  [귀무가설]              [대립가설]

#     **                #     **      ||
#    *||*               #    *  *    ||||
#   *||||*              #   *    *  ||||||
#  *||||||*             #  *      |||||||||
# *||||||||*            # *      ||*||||||||
# -----|-----           # -----|-------|-------
#   μ1 == μ2            #      μ1  !=  μ2

# 04_가설과 오차범위 

# 위의 그림에서와 왼쪽 그림과 같이 μ1 == μ2인 경우에는 당연히 귀무가설을 채택함
# 그러나 오른쪽 그림과 같은 상황이 발생하였을 경우 귀무가설 채택 / 기각의 거리를 어느정도 수준으로 해야 할 것인가가 중요함
# 이러한 범위를 나타내는 것이  바로 오차범위임

library(tigerstats)  # install.packages("tigerstats")
pnormGC(c(-1.64, 1.64), region="between", mean=0, sd=1, graph=TRUE)  # 유의수준 0.01 = 90% 신뢰구간
pnormGC(c(-1.96, 1.96), region="between", mean=0, sd=1, graph=TRUE)  # 유의수준 0.05 = 95% 신뢰구간
pnormGC(c(-2.58, 2.58), region="between", mean=0, sd=1, graph=TRUE)  # 유의수준 0.01 = 99% 신뢰구간

#     **      ||
#    *  *    ||||           |--> μ1과 μ2가 오차범위 내에 있을 정도라고 할 정도로 차이가 작다면 => 귀무가설 채택
#   *    *  ||||||          |    μ1과 μ2가 오차범위를 벗어날 정도로 차이가 크다면              => 귀무가설 기각
#  *      |||||||||         |
# *      ||*||||||||      |  #---------------------------------------------------------------------------------
# -----|-------|-------     |  # 기준1: p-value가 0.05보다 높다면[p > 0.05] => 귀무가설 채택
#      μ1  !=  μ2           |  #        귀무가설은 관습적이고 보수적인 주장 => '차이가 없다', '0이다', '상관없다'
#      |-------|            |  # 기준2: p-value가 0.05보다 낮다면[p < 0.05] => 귀무가설 기각하고 대립가설 채택
#       오차범위------------|  #        대립가설은 적극적으로 입증하려는 주장 => '차이가 있다', '상관있다'
#---------------------------------------------------------------------------------

# 05_가설설정에 따른 오류

# 1) 우리는 가설설정을 통하여 두 데이터가 동일한지 아닌지를 비교할 수 있으나 => 사실 어느 가설검정도 100% 확실하지 않음

# 검정은 확률을 기반으로 하기 때문에 항상 잘못된 결론을 내릴 수 있음
# 가설검정 수행에 있어서도 [1종 오류]와 [2종 오류]라는 두 가지 유형의 오류가 발생할 수 있음

source("http://159.223.63.63:3838/data/inference/alpha_beta_error.R")
alpha_beta

# 2) α오류와 β오류의 구분

# 두 오류의 위험은 역의 관계가 있으며 검정의 유의수준 및 검정력에 의해 결정됨
# 따라서 위험을 정의하기 전에 어느 오류가 상황에 더 심각한 결과를 초래하는지 확인해야 함     
# 제1종 오류(alpha 오류): 귀무가설이 참(차이가 없음)인데도 불구하고 귀무가설을 기각(=차이가 있음)하는 오류
# 제2종 오류(beta 오류) : 귀무가설이 거짓(차이가 있음)인데 불구하고 귀무가설을 채택(=차이가 없음)하는 오류

#                                   사 실
#------------------|------------------|-----------------------  
#                  |       H0 참      |      H0 거짓
#------------------|------------------|-----------------------  
# 가설| H_0 기각 X |  옳은 결정(1-α)  |   2종오류(β)
# 판정|------------|------------------|-----------------------
#     | H_0 기각 O |  1종오류 (α)     |   옳은 결정(1-β)
#-------------------------------------------------------------

# 3) α오류와 β오류의 이해 

# 형사재판은 '피의자 = 범인 X'라는 가정 하에서 이루어짐
# 재판결과 피의자 = 범인 아니면 귀무가설 채택 (가정과 실제 결과가 동일함, 차이가 없음: H0 채택)
# 반대로   피의자 = 범인 이면   귀무가설 기각 (가정과 실제 결과가 동일하지 않음, 차이가 있음: H0기각)
#-------------|----------------------------------------------------------------------------------------------------#
# 제1종오류(α)|피의자가 사실은 범인이 아닌데도 재판 결과 판사가 범인으로 구속하는 오류
#             |                ---------------            -----------
#             |                귀무가설이 맞음에도 --> 귀무가설을 기각하는 오류
#-------------|----------------------------------------------------------------------------------------------------#
# 제2종오류(β)| 피의자가 사실은 범인임에도 불구하고 재판 결과 무죄로 풀어주는 오류
#             |                 ----------                    ---------------          
#             |                 귀무가설이 틀림에도----> 귀무가설을 채택하는 오류
#-------------|----------------------------------------------------------------------------------------------------#

# 4) α오류와 β오류의 선택

# 분석할 때 1종 오류(α)와 2종 오류(β)가 모두 동시에 나타남 => 문제는 두 가지 오류를 동시에 줄이기 어렵다는 것임
# 따라서 우리는 선택과 집중을 할 필요 있음 ---> 어떻게? 
# 1종 오류가 나타났을 때 보다 2종 오류가 나타났을 때 위험의 강도가 훨씬 적기 때문에 '차라리 2종 오류를 범하는 편을 택함'
#                                                                                   -----------------------------------

# 5) 유의수준과 유의확률

# 우리가 때려잡기로 결정한 오류(α오류)는 귀무가설(H0)과 대립가설(H1) 설정의 기준이 됨 => 유의수준(α 값)은 1%, 5%, 10% 등 사용함
# 한편, 유의확률(p값)은 실제 도출된 확률값을 의미함
# 따라서, 유의수준 5% 이하(p < 0.05)는 가설검정 결과가 사실이 아닐 가능성(오류 가능성)이 5% 이하라고 해석할 수 있음

library(tigerstats)  # install.packages("tigerstats")
pnormGC(c(-1.64, 1.64), region="between", mean=0, sd=1, graph=TRUE)  # 유의수준 0.01 = 90% 신뢰구간
pnormGC(c(-1.96, 1.96), region="between", mean=0, sd=1, graph=TRUE)  # 유의수준 0.05 = 95% 신뢰구간
pnormGC(c(-2.58, 2.58), region="between", mean=0, sd=1, graph=TRUE)  # 유의수준 0.01 = 99% 신뢰구간


# 06_가설분석의 네 가지 단계

# 앞에서 이야기 했던 복잡한 내용을 네 단계로 다시 한번 정리하면 다음과 같음

# 1단계:가설의 설정: 귀무가설과 대립가설 설정, 단측검정과 양측검정 결정
 # 어떠한 살인사건이 발생하였고, A라는 용의자가 체포되어 법정에 섰을 때 다음과 같은 두 가지 가설을 세울 수 있음
 # 대립가설: 살인사건의 범인은 A / 귀무가설: A는 살인사건의 범인이 아님
 # 이미 가설설정에서 A라는 사람의 편견이 들어가 있으니 '단측검정'

# 2단계: 검정통계량 계산: 대립가설이 맞는지, 귀무가설이 맞는지 증거를 찾아서 분석하는 과정
 # 평균으로 비교 -> z-분포, t-분포, F분포
 # 분산으로 비교 -> 카이제곱 분포

# 3단계: 유의수준 결정과 p값 분석   
 # 살인사건이 발생할 경우 재판 과정에서 나타나는 두 가지 오류 가운데 -> 선택과 집중 원칙에 의하여 1종 오류만 최소화(난 한 놈만 때려잡어!!!)
 # 1) 살인을 하지 않았는데 살인했다고 판정하는 경우  -> 1종 오류
 # 2) 살인했는데 살인하지 않았다고 판정하는 경우     -> 2종 오류

# 4단계: 해석
 # 1종 오류를 최소화 하기 위해서는 -> '분석결과가 오류'일 가능성을 나타낼 수 있는 최소범위를 잡아주어야 함
 # 즉, 유의수준을 정해 주어야 함 -> 일반적으로 5%(0.05)를 많이 사용함 
 # (= 분석 결과 오류가 나타날 최대 확률은 5% 미만이어야 한다고 선언)

 # 1종 오류가 나타날 확률을 보다 명확하게 수치화 한 것 -> p값 
 # 따라서 1종 오류가 나타날 확률이 높다면(p 값이 높다면[p>0.05]) -> A는 살인범이 아님(무죄) => 귀무가설(H0) 채택
 # 반대로 1종 오류가 나타날 확률이 작다면(p 값이 작다면[p<0.05]) -> A는 살인범       (유죄) => 귀무가설(H0) 기각, 대립가설(H1) 채택


#------------------------------------
# 3_명목형 자료의 비교: 카이제곱 검정
#------------------------------------

# 01_카이제곱 분석(교차분석)이란? 

# 범주형 변수(명목/서열)들에 대한 교차빈도 통계량 분석기법
# 이 가운데 가장 많이 사용되는 분석방법이 카이제곱(χ^2) 교차분석 기법 
#                                         --------------
# 독립 및 종속변인 모두가 명목변수로 측정된 데이터에서 사용할 수 있는 분석 방법

# 02_카이제곱 분석의 원리

# (1) 각각의 범주에 대한 실제 발생 빈도를 교차 테이블로 정리함                 -> 관측빈도 
# (2) 통상적 또는 일반적으로 이렇게 될 것이다라는'상식'을 교차 테이블로 정리함 -> 기대빈도
# (3) 관찰빈도와 예측빈도를 비교함(카이제곱 검정통계량 활용)
#-----------------------------------------------------------------------------------#
#     if, 관찰빈도 == 기대빈도 ----> 각각의 변인은 상호 독립적
#     if, 관찰빈도 != 기대빈도 ----> 변인은 상호 독립적이지 않고 연관성을 가지고 있음 
#-----------------------------------------------------------------------------------#

# 03_카이제곱 실습: 가족의 규모에 따라 구매한 세탁기의 크기가 다른가?

# (1) 설문조사 설계

# 대상: 주부 300명 

# 설문 1: 귀하의 가족은 모두 몇 몇입니까?  (1) 1~2명  (2) 3~4명 (3) 5명 이상
# 설문 2: 귀하의 세탁기는 다음 중 어디에 해당합니까?: (1) 소 (2) 중 (3) 대

# (2) 설문조사 정리: 교차테이블 만들기

#       1-2  3-4  5 이상
#------------------------
# 소형 | 25  37   8 | 70
# 중형 | 10  62  53 | 125
# 대형 |  5  41  59 | 105
#------------------------
# 합계 | 40 140 120 | 300

# (3) 연구가설 설정

# [관찰빈도 == 기대빈도] => 가족규모와 세탁기 크기는 독립적 O(H0) => 연관성 X
# [관찰빈도 != 기대빈도] => 가족규모와 세탁기 크기는 독립적 X(H1) => 연관성 O
#---------------------------------------------------------------------------------
# 기준1: p-value가 0.05보다 높다면[p > 0.05] => 귀무가설 채택
#        귀무가설은 관습적이고 보수적인 주장 => '차이가 없다', '0이다', '상관없다'
# 기준2: p-value가 0.05보다 낮다면[p < 0.05] => 귀무가설 기각하고 대립가설 채택
#        대립가설은 적극적으로 입증하려는 주장 => '차이가 있다', '상관있다'
#---------------------------------------------------------------------------------

# (4) 기대빈도 계산

#-----------------------------------------------#                 
#               (해당 행의 합 × 해당 열의합)    #
# 기대값 공식 = -----------------------------   #
#                       전체 표본수             #
#-----------------------------------------------#

(70/300 * 40/300)* 300    # = 9.33    #      | 1-2    3-4   5 이상 
(70/300 * 140/300)* 300   # = 32.67   #----------------------------
(70/300 * 120/300)* 300   # = 28      # 소형 |  9.33  32.67  28.00 
                                      # 중형 |   -      -      - 
                                      # 대형 |   -      -      - 
# (5) 실습

# 데이터 프레임 만들기
v1 <- c(25, 37, 8)
v2 <- c(10, 62, 53)
v3 <- c(5, 41, 59)
laundary <- cbind(v1, v2, v3)
laundary <- as.data.frame(laundary)
colnames(laundary) <- c("1~2", "3~4", "5~6")
rownames(laundary) <- c("소형", "중형", "대형")
laundary

# 카이제곱(X^2) 통계량 검정
chisq.test(laundary)

#-----------------------------------------------------  
# Pearson's Chi-squared test
# 
# data:  laundary
# X-squared = 58.208, df = 4, p-value = 6.901e-12
#-----------------------------------------------------

# 해석: 검정통계량 -> 58.21  / 자유도 -> 4
# 통계적 의미: p < 0.05  => 대립가설(H1) 채택(가족규모와 세탁기 크기는 연관성 O)
#---------------------------------------------------------------------------------
# 기준1: p-value가 0.05보다 높다면[p > 0.05] => 귀무가설 채택
#        귀무가설은 관습적이고 보수적인 주장 => '차이가 없다', '0이다', '상관없다'
# 기준2: p-value가 0.05보다 낮다면[p < 0.05] => 귀무가설 기각하고 대립가설 채택
#        대립가설은 적극적으로 입증하려는 주장 => '차이가 있다', '상관있다'
#---------------------------------------------------------------------------------

rm(list=ls()) 


#------------
# 4_t-검정
#------------

# 01_t-검정의 원리

# t-분포는 기본적으로 표본/모집단의 평균 차이가 0 인지 아닌지를 판단할 때 사용함

# 한 예로 어떤 맥주는 알콜 도수가 4.2%일 경우에만 판매할 수 있다고 할 때
# 원료가 조금씩 다르고, 양조과정의 미묘한 차이로 모든 맥주의 알콜도수가 4.2%가 될 수는 없음
# 따라서 통계학자들은 샘플을 뽑아 테스트 해야 함

# 맥주 다섯 병을 뽑아 알콜 도수를 측정
# 샘플맥주 5병의 알콜 도수를 4.2(X지점)로 볼 수 있는가?
# (5개 샘플과 전체평균은 동일한가?)

#       병1     병2  병3   병4      병5
#      ---0--------0—X—0-----0---------0-------  
#       4.15    4.19   4.21 4.23    4.27       

# 첫번째 단계: 평균의 차이(편차) 파악하기 => 0.01
((4.15-4.2)+(4.19-4.2)+(4.21-4.2)+(4.23-4.2)+(4.27-4.2)) / 5 

# 두 번째 단계: 분산 구하기 => 0.02
((-0.05-0.01)^2 + (-0.01-0.01)^2 + (0.01-0.01)^2 + (0.03-0.01)^2  + (0.07-0.01)^2) / (5-1)

# 세 번째 단계: 평균차이(0.01%)를 표준편차(0.02%)로 나누기
0.01 / 0.02  # t-통계량 => 데이터의 평균 차이 보다 퍼져있는 차이(분산)가 두 배 이상 큼
             #                      (signal)      <            (noise)

# 02_t-검정 매커니즘

# t-검정은 두 집단 간 평균을 비교하는 통계분석 기법
# 다시 말해 t-검정은 두 집단 간 평균 차이에 대한 통계적 유의성을 검증하는 방법
#                    -------------------
#                 => 두 집단이 퍼져 있는 정도(분산)와 몰려있는 정도(평균)을 비교하여 집단 간 차이 유무 분석
#                             --------------------    -------------------
#             _        _             noise                    signal
#             X_T      X_C             |                         |
#             |         |              |-------------------------|
#  |          |  signal |                                    |
#  |          |---------|              # # # # # #    귀무(H0): noise < signal => 두 집단은 통계학적으로 차이가 없음
#  |         # #      * *              #  signal  #   대립(H1): noise > signal => 두 집단은 통계학적으로 차이가 있음
#  |control #   #    *   *             #  ------  #     
#  | group #     #  *     *   <<====   #  noise   # 
#  |      #       #        *           # # # # # #                
#  |    #       *   #        *                      
#  |  #       *       #         * treatment group                  
#  |_______________________________                 
#    |----------------|                     
#     noise1 |------------------|
#    (Var_T)       noise2       
#                 (Var_C)  

#                         [Var_T   Var_C]                   각 표본의 분산(= 집단변화량)을 해당 표본크기로 나눈 후
# (1) noise(분모) =  Root [----- + -----] = SE(X_T -X_C) => 그 값들을 합하여 제곱근 한 것임
#                         [ n_T     n_C ]                   (따라서 표본크기[n]가 증가한다면 noise는 점차 감소함)

#                _    _
# (2) 분자계산 = X_T -X_C  [ 두 집단의 평균의 차이]   

#
#          (2)     => 두 집단의 평균의 차이가 클수록 t 값은 증가함
# (3) t = --------
#          (1)     => 표본의 크기가 많아질수록 t 값은 작아짐
#                     분산이 작을수록(=데이터가 몰려 있을수록) t값은 작아짐

# 03_분석절차: 평균을 비교함에 있어서(t-검정) 무엇을 고려해야 하는가?
                                                                            
# (1) 비교하고자 하는 데이터가 연속변수인가? ..................... Yes / NO → MWW(만-위트니-윌콕슨 검정)
#                                                                   ↓  
# (2) 비교하고자 하는 데이터가 정규분포를 따르고 있는가? ......... Yes / NO → MWW
#                                                                   ↓
# (3) 비교하고자 하는 데이터가 등분산인가? ....................... Yes / NO → Welch's t-test
#                                                                   ↓
#                                                             student t-test

# 04_다양한 t-검정: 

# 데이터의 형식과 분석하고자 하는 내용에 따라 크게 세 가지로 구분됨

# (1) 단일표본 t 검정: 샘플 맥주 5병의 평균알콜 도수가 전체평균과 통계적으로 동일하다고 볼 수 있는가?

a <- c(4.15, 4.19, 4.21, 4.23, 4.27)  # 맥주 샘플 5병의 알콜도수
shapiro.test(a)   # 정규성 검정: [p > 0.05] => 귀무가설 채택 => (정규분포와) 차이없음 => 정규분포를 따름 

#  [p < 0.05] => 귀무가설 기각 => (정규분포와) 차이있음 => 정규분포를 따르지 않음 
t.test(a, mu=4.2, alternative="two.sided") 

# (2) 독립표본 t 검정: 2020 강남구 개포동 / 용산구 이촌동의 40평대 아파트 거래가격 샘플
#                      두 지역의 아파트 거래 가격이 동일하다고 볼 수 있는가?

gaepo <- c(28.4, 27.9, 28.9, 29.2, 28.7, 29.5, 28.5, 27.9, 30.6, 29.8) ; mean(gaepo)
ichon <- c(28.1, 29.1, 29.7, 27.3, 28.4, 30.5, 29.8, 30.0, 30.6, 29.0) ; mean(ichon)

plot(density(gaepo)) ; lines(density(ichon), lty=2, col="red")  # 두 지역의 아파트 매매가 분포(직관적으로 b가 더 큼)

shapiro.test(gaepo)  # 정규성 검정: [p > 0.05] => 귀무가설 채택 => (정규분포와) 차이없음 => 정규분포를 따름 
shapiro.test(ichon)  #              [p > 0.05] => 귀무가설 채택 => (정규분포와) 차이없음 => 정규분포를 따름       
# gaepo와 ichon 모두 [p > 0.05] 를 만족시킴 => 귀무가설 채택 => 정규분포 따름 => 등분산 테스트로 넘어감

var.test (gaepo, ichon) # gaepo와 ichon가 등분산인지 F-검정하라 => p=0.5079 이므로 귀무가설 채택 [p > 0.05]
#-------------------------------------------------------------------------------------
# 기준1: p-value가 0.05보다 높다면[p > 0.05] => 귀무가설 채택
#        귀무가설은 관습적이고 보수적인 주장 => '차이가 없다', '0이다', '상관없다'
# 기준2: p-value가 0.05보다 낮다면[p < 0.05] => 귀무가설 기각하고 대립가설 채택
#        대립가설은 적극적으로 입증하려는 주장 => '차이가 있다', '상관있다'
#--------------------------------------------------------------------------------------
# 등분산 검정 결과 등분산(var.equal=TRUE)이라는 결과가 도출되었으니 t-검정 실시함

t.test (gaepo, ichon, var.equal=TRUE)

# t-검정 결과 통계량은 0.71로 낮게 나온 편임(부호는 아무런 의미 없음) => (signal) < (noise)
# 개포동과 이촌동의 평균 거래가격은 28.94와 29.25 임
# p = 0.4844로 [p > 0.05] => 귀무가설 채택 => 두 지역의 매매가는 통계학적으로 차이가 없음

# (3) 대응표본 t 검정: 스타필드 신축이 주변 아파트 거래량에 영향을 미치는가 ?[전후비교]
before = c(16, 20, 21, 22, 23, 22, 27, 25, 27, 28)
after  = c(19, 22, 24, 24, 25, 25, 26, 26, 28, 32)
shapiro.test(before)  # 정규성 검정: [p > 0.05] => 귀무가설 채택 => (정규분포와) 차이없음 => 정규분포를 따름 
shapiro.test(after)  #               [p > 0.05] => 귀무가설 채택 => (정규분포와) 차이없음 => 정규분포를 따름 

# before와 after 모두 [p > 0.05] 를 만족시킴 => 귀무가설 채택 => 정규분포 따름 => 등분산 테스트로 넘어감

var.test (before, after) # before와 after가 등분산인지 F-검정하라 
# p= 0.8205 => [p > 0.05]를 만족시키므로 귀무가설 채택 => before와 after의 분산은 차이없음 => 등분산 만족함

# 등분산 검정 결과 before와 after 모두가 등분산이라는 결과가 도출되었으니 t-검정 실시함
t.test(before, after, paired=TRUE) # t값이 4.4721로 상당히 큼(두 집단에 상당한 차이를 보임)
                                   # (signal) > (noise) : 시그널이 노이즈에 비하여 네 배 큼
# [p < 0.05] => 대립가설 채택 => 스타필드 건축이 주변지역 아파트 거래량에 영향을 미침
# 통계학적으로 스타필드의 입주는 주변 아파트 거래량에 영향을 미침 


#------------
# 5_ANOVA
#------------

# 01_F-검정이란?

# 한 마디로 t-검정의 확장판 => t-검정은 두 집단의 차이를 (평균/분산을 사용하여) 통계적으로 규명 => t-검정
#                           => F-검정은 세 집단의 차이를 (평균/분산을 사용하여) 통계적으로 규명 => ANOVA

# 02_왜 세집단의 차이 검정에서 t-검정(평균비교)을 사용할 수 없는가?

# (1) t검정은 A-B 두 집단의 평균값 비교만 가능 -> 따라서 비교대상 집단이 증가한다면 문제가 복잡해짐
#     만약 A-B-C-D-E 다섯 집단의 평균값을 이용하여 집단의 차이를 비교한다면 -> 10회의 t-검정이 필요함(개노가다!) => 5C2
choose(5,2) # 5C2: (5 Combination 2 = 4 + 3 + 2 + 1 = 10) 

# (2) 둘째, 두 가지 집단 이상을 비교하였을 때 -> 앞에서 언급한 두 가지 오류 가운데 1종 오류를 범할 수 있는 확률이 증가함
#     즉, 비교 대상이 증가할수록(2개에서 3~4개로 비교대상 그룹이 증가할 수록 비교할 때(pair-wise comaprison)
#     1종 오류(참을 거짓으로 판정할 오류)가 애초 정한 유의수준 α(significance level α)에 비하여 크게 증가하기 때문임 
#     만약 유의수준 α (significance level α) = 0.05라고 한다면, 10번의 t-Test를 각각 독립적으로 하고 나면 
#     제1종 오류가 생길 확률은 1 - (0.95)^10 = 0.4012631로 증가하게 됨 (오류 확률이 누적되서!!!)
#     이는 처음의 유의수준 α 0.05보다 약 8배  증가 ->  즉,1종 오류가 생길 확률도 약 8배 증가한다는 의미임 

# (3) t-검정의 한계를 극복하기 위해서는 무엇을 해야 하는가? => 분산분석
#     그렇다면 이러한 t-검정의 구조적 한계를 피하기 위하여 우리는 어떠한 조치를 취해야 하는가?
#     분석을 단 한 큐에 끝내버리면 됨 -> 여러 개의 그룹을 한번에 비교하게 되면 오류의 누적으로 유의수준 α가 증가할 
#     가능성을 차단할 수 있음 ==> 이것을 다중비교(multiple comparison), 분산분석이라고 함


# 03_분산분석을 구성하는 핵심적 요소는? 요인(factor)

# ex) 동성연애에 대한 인식 차이: 기독교, 불교, 천주교 구분 연구를 수행한다고 할 때 다음과 같은 가설을 수립할 수 있음
# 귀무가설(H0): [p > 0.05] => 종교에 따라 동성연애에 대한 인식 차이가 없음
# 대립가설(H1): [p < 0.05] => 종교에 따라 동성연애에 대한 인식 차이가 있음

# 위의 사례에서는 종교 그룹이 3개 이기 때문에 -> t-검정을 사용하기가 번잡스러움 -> 따라서 분산분석을 사용함
# 분산분석을 하기에 앞서서 일단 집단을 구분해야 함 -> 종교를 3가지 요인(factor)으로 분류해야 함
# 따라서, 분산분석은 요인에 따라 종속변수의 값이 달라지는 지를 분석하는 것임
# 결과적으로 요인이 일종의 독립변수(설명변수) 역할을 수행함        


# 04_분산분석 절차: 3개의 관문을 통과해야 약속의 땅 ANOVA에 도착할 수 있다?

# (1) 비교하고자 하는 데이터가 연속변수인가? ..................... Yes / NO → Kruskal-Wallis H test
#                                                                   ↓
# (2) 비교하고자 하는 데이터가 정규분포를 따르고 있는가? ......... Yes / NO → Kruskal-Wallis H test
#                                                                   ↓
# (3) 비교하고자 하는 데이터가 등분산인가? ....................... Yes / NO → Welch's ANOVA
#                                                                   ↓
#                                                                 ANOVA 

# 05_ANOVA 문제풀이1: 일원분산분석(요인1, 변수1)

# 까페 창업 위하여 15개(3개 대학 주변) 점포의 하루 매출액 비교함(단위: 10만)
# 지역에 따라 매출액의 차이가 있는가?
  
#             (한양) (연세) (홍익) 
#   관측치      HY    YS     HI
# -------------------------------
#     1        21   25    28 
#     2        22   27    28     # 귀무(H0): 지역에 따라 매출액이 다르지 않음
#     3        21   26    27     # 대립(H1): 지역에 따라 매출액이 다름
#     4        22   26    29    
#     5        20   26    28
#--------------------------------
# Total Mean   21   26    28    -> 전체평균 25

#------------------------------------#
#       HY       YS          HI      #
#      평균      평균        평균    #
#     (21)       (26)        (28)    #
#      |----------|-----------|      ==> 집단 간 변동(SSTR) -> 지역이 달라서 나타나는 차이(집단적 특성) 
#                                    #
#  |------|  |-------|  |---------|  ==> 집단 내 변동(SSE)  -> 매장특성이 달라서 나타나는 차이(개별적 특성)
#     1        0.707       0.707     #
#      |---------------------|       ==> 총변동(SST)   
#                                    #
#-----------------------------------------------------#
#  SST(총변동)  = SSTR(집단간편차) + SSE(집단내편차) ==> [실험요인] => 지역이 달라서 나타나는 차이
#                 ----------------   --------------   #
#                 통제가능 요인     통제 불가능 요인 ==> [외생요인] => 매장특성이 달라서 나타나는 차이
#               [실험(내생)요인]    [외생요인]        #
#-----------------------------------------------------#

# 06_ANOVA 분석

# (1) 데이터 구축하기

v1 <- c(21, 22, 21, 22, 20, 25, 27, 26, 26, 26, 28, 28, 27, 29, 28)
v2 <- c("HY","HY","HY","HY","HY","YS","YS","YS","YS","YS","HI","HI","HI","HI", "HI")
coffee <- cbind(v1,v2)
coffee <- as.data.frame(coffee)
coffee$v1 <- as.numeric(as.character(coffee$v1))
colnames(coffee) <- c("sale", "region")
head(coffee)

# (2) 기초통계 보기

summary(coffee)
boxplot(coffee)

# (3) 속성 확인하기: 

class(coffee$sale) ; class(coffee$region)
# sale => numeric , region => factor     

# (4) 기본조건(NID)을 만족하는지 검정하기: 정규성 검정

shapiro.test(coffee$sale) 
# 해석: 귀무가설(H0) [p > 0.05]: 데이터가 정규분포를 따름
#       대립가설(H1) [p < 0.05] : 데이터가 정규분포를 따르지 않음

# (5) 기본조건(NID)을 만족하는지 검정하기: 등분산성 검정 

# 등분산을 검정하는 방법은 Levene 테스트와 Bartlett 테스트로 구분됨
# 일반적으로 Levene 테스트를 많이 사용함
# (Bartlett 테스는 Levene 테스트와 달리 정규분포 테스트를 통과한 경우에만 제한적으로 사용 가능함)

library(lawstat)   # install.packages("lawstat")
levene.test(coffee$sale, coffee$region)

# 해석: 귀무가설(H0) [p > 0.05]: 모든 집단의 분산은 차이가 없다.
#       대립가설(H1) [p < 0.05] : 적어도 하나 이상의 집단의 분산에 차이가 있음  
# 참고: Bartlett 테스트 함수식 => bartlett.test(Time ~ Company, data = phone) 

# NID 결과 => 정규성 검정 / 등분산성 검정 모두 통과


# (6) AOV(Analysis Of Variance) 실행

avol <- aov(coffee$sale ~ coffee$region)  
summary(avol) # 통화시간 sale(종속변수)이 region(독립변수)에 따라 차이가 있는지를 ANOVA로 집단간 비교

# Pr(>F) = 3.8e-08 ***  ==> p > 0.05 => 귀무가설 기각 / 대립가설 채택 => 0이 아님, 차이가 있음

# (7) 종합: 분산분석표 그려보자 

#--------------------------------------------------------------------------------------------
# 변동 원인               제곱합  자유도      분산                     분산비율(F값)
# --------------------------------------------------------------------------------------------
# 처리(SSTR): 실험요인    122.1      2     122.1/2 = 61.05(MSTR)   61.05/0.57 = 107.1 (MSTR/MSE)
# 오차(SSE) : 외생요인      6.8     12      6.8/12 =  0.57(MSE)
# -----------------------------------------------------------------------------------------
# 전체(SST):총계          128.9     14

# (8) 종합: F값(분산비율)에 대한 해석

# F 통계량은 처리(SSTR)의 크기에 영향을 받음
#            ----------      
#            -> 처리(SSTR: 집단 간 편차)가 커지면 오차(SSE: 집단 내 편차)가 작아짐 
#            -> 즉, F 통계량의 분자 커짐 / 분모 작아짐 -> F 값 증가하게 됨 
# F 통계량 값이 크다는 것은 =?> 그룹 간의 차이가 크다는 말임

# 지역이 달라서 나타나는 매출액 차이가 개별매장 특성이 달라서 나타나는 차이보다 107.1 배가 큼
# => 지역에 따라 매출액 차이가 존재함